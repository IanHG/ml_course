\documentclass[]{article}

\input{../../../header.tex}

\usepackage{pgfplots}
\pgfplotsset{compat=1.13}

\usetikzlibrary{external}\tikzexternalize
\usetikzlibrary{shapes}   % for diamond shape
\usetikzlibrary{fit}   % for diamond shape
\usetikzlibrary{shadows.blur}
\usetikzlibrary{decorations.pathreplacing}

\pgfdeclarelayer{bg}    % declare background layer
\pgfsetlayers{bg,main}  % set the order of the layers (main is the standard layer)

% Draw input layer
\newcommand{\drawinputlayer}[1]{
   \foreach \name / \y in {1,...,#1}
   % This is the same as writing \foreach \name / \y in {1/1,2/2,3/3,4/4}
      \node[input neuron, pin={[pin edge={line width=0.3mm}]left:Input \y}] (I-\name) at (0,-\y) {};
}

% Draw hidden layer
\newcommand{\drawhiddenlayer}[3]{
   \foreach \name / \y in {1,...,#1}
      \path[yshift=#3cm]
         node[hidden neuron] (H#2-\name) at (#2 * \layersep, -\y cm) {};
}

% Draw output layer
\newcommand{\drawoutputlayer}[2]{
   \foreach \name / \y in {1,...,#1}
      \path[yshift=-0.5cm]
         node[output neuron, pin={[pin edge={->, line width=0.3mm}]right:Output \y}] (O-\name) at (#2 * \layersep, -\y cm) {};
}

% Connect layers
\newcommand{\connectlayers}[4]{
   \foreach \source in {1,...,#2}
      \foreach \dest in {1,...,#4}
         \path (#1-\source) edge[line width=0.3mm] (#3-\dest);
}

\begin{document}
\def\layersep{2cm}
\begin{tikzpicture}[font=\large]
   \tikzstyle{arrow}=[->,draw=black!70, node distance=\layersep]
   \tikzstyle{every pin edge}=[<-,shorten <=1pt]
   \tikzstyle{neuron}=[circle,thick,draw=black,minimum size=17pt,inner sep=0pt]
   \tikzstyle{input}=[text=blue,minimum size=22pt];
   \tikzstyle{weight}=[neuron, minimum size=22pt];
   \tikzstyle{sum}=[neuron, minimum size=30pt];
   \tikzstyle{activation}=[neuron, rectangle, minimum size=30pt];
   \tikzstyle{annot} = [text width=20em, text centered];
   \tikzstyle{layerbg} = [rectangle, rounded corners];

   %\begin{axis}[
   %      ymin=0, ymax=1,
   %      xmin=-1, xmax=1,
   %      samples=50,
   %   ]
   %   \addplot[blue, ultra thick] {exp(x)};
   %\end{axis}  
   \begin{axis}[
         name=relu,
         axis line style = thick,
         xmin=-1, xmax=1,
         ymin=-0.2, ymax=1.2,
         xtick={0},
         ytick={0,1},
         xlabel={$z$},
         ylabel={$g(z) = \max(0,z)$},
         no markers,
         samples=500
      ]
      %\addplot[blue,thick] {1/ ( 1 + exp(-x))};
      \addplot[blue,very thick] {max(0, x)};
   \end{axis}
   
   \node[annot, yshift=0.5cm] at (relu.north) (xa) {Rectified Linear Unit (ReLU)};

\end{tikzpicture}

\begin{tikzpicture}[font=\large]
   \tikzstyle{arrow}=[->,draw=black!70, node distance=\layersep]
   \tikzstyle{every pin edge}=[<-,shorten <=1pt]
   \tikzstyle{neuron}=[circle,thick,draw=black,minimum size=17pt,inner sep=0pt]
   \tikzstyle{input}=[text=blue,minimum size=22pt];
   \tikzstyle{weight}=[neuron, minimum size=22pt];
   \tikzstyle{sum}=[neuron, minimum size=30pt];
   \tikzstyle{activation}=[neuron, rectangle, minimum size=30pt];
   \tikzstyle{annot} = [text width=20em, text centered];
   \tikzstyle{layerbg} = [rectangle, rounded corners];

   %\begin{axis}[
   %      ymin=0, ymax=1,
   %      xmin=-1, xmax=1,
   %      samples=50,
   %   ]
   %   \addplot[blue, ultra thick] {exp(x)};
   %\end{axis}  
   \begin{axis}[
         name=relu,
         axis line style = thick,
         xmin=-1, xmax=1,
         ymin=-0.2, ymax=1.2,
         xtick={0},
         ytick={0,1},
         xlabel={$z$},
         ylabel={$g(z) = \max(0,z) + \alpha \min(0, z)$},
         no markers,
         samples=500,
         legend pos=north west,
      ]
      %\addplot[blue,thick] {1/ ( 1 + exp(-x))};
      \addplot[blue,very thick] {max(0, x) + 0.01 * min(0, x)};
      \addlegendentry{$\alpha = 0.01$}
      \addplot[red,very thick] {max(0, x) + 0.2 * min(0, x)};
      \addlegendentry{$\alpha = 0.1$}
      \addplot[green,very thick] {max(0, x) + 0.5 * min(0, x)};
      \addlegendentry{$\alpha = 0.5$}
   \end{axis}
   
   \node[annot, yshift=0.5cm] at (relu.north) (xa) {Leaky/Parametric Rectified Linear Unit (PReLU)};

\end{tikzpicture}

\begin{tikzpicture}[font=\large]
   \tikzstyle{arrow}=[->,draw=black!70, node distance=\layersep]
   \tikzstyle{every pin edge}=[<-,shorten <=1pt]
   \tikzstyle{neuron}=[circle,thick,draw=black,minimum size=17pt,inner sep=0pt]
   \tikzstyle{input}=[text=blue,minimum size=22pt];
   \tikzstyle{weight}=[neuron, minimum size=22pt];
   \tikzstyle{sum}=[neuron, minimum size=30pt];
   \tikzstyle{activation}=[neuron, rectangle, minimum size=30pt];
   \tikzstyle{annot} = [text width=20em, text centered];
   \tikzstyle{layerbg} = [rectangle, rounded corners];

   %\begin{axis}[
   %      ymin=0, ymax=1,
   %      xmin=-1, xmax=1,
   %      samples=50,
   %   ]
   %   \addplot[blue, ultra thick] {exp(x)};
   %\end{axis}  
   \begin{axis}[
         name=relu,
         axis line style = thick,
         xmin=-1, xmax=1,
         ymin=-0.2, ymax=1.2,
         xtick={0},
         ytick={0,1},
         xlabel={$z$},
         ylabel={$g(z) = \left| z \right|$},
         no markers,
         samples=500,
         legend pos=north west,
      ]
      %\addplot[blue,thick] {1/ ( 1 + exp(-x))};
      \addplot[blue,very thick] {max(0, x) - 1.0 * min(0, x)};
   \end{axis}
   
   \node[annot, yshift=0.5cm] at (relu.north) (xa) {Absolute Rectified Linear Unit};

\end{tikzpicture}

\begin{tikzpicture}[font=\large]
   \tikzstyle{arrow}=[->,draw=black!70, node distance=\layersep]
   \tikzstyle{every pin edge}=[<-,shorten <=1pt]
   \tikzstyle{neuron}=[circle,thick,draw=black,minimum size=17pt,inner sep=0pt]
   \tikzstyle{input}=[text=blue,minimum size=22pt];
   \tikzstyle{weight}=[neuron, minimum size=22pt];
   \tikzstyle{sum}=[neuron, minimum size=30pt];
   \tikzstyle{activation}=[neuron, rectangle, minimum size=30pt];
   \tikzstyle{annot} = [text width=20em, text centered];
   \tikzstyle{layerbg} = [rectangle, rounded corners];

   %\begin{axis}[
   %      ymin=0, ymax=1,
   %      xmin=-1, xmax=1,
   %      samples=50,
   %   ]
   %   \addplot[blue, ultra thick] {exp(x)};
   %\end{axis}  
   \begin{axis}[
         name=relu,
         axis line style = thick,
         xmin=-5, xmax=5,
         ymin=-0.2, ymax=1.2,
         xtick={0},
         ytick={0,1},
         xlabel={$z$},
         ylabel={$g(z) = \sigma(z) = {1 \over \left( 1 + e^{-\alpha z} \right)}$},
         no markers,
         samples=500,
         legend pos=north west,
      ]
      \addplot[blue,thick] {1/ ( 1 + exp(-0.5*x))};
      \addlegendentry{$\alpha = 0.5$}
      \addplot[red,thick] {1/ ( 1 + exp(-1.0*x))};
      \addlegendentry{$\alpha = 1.0$}
      \addplot[green,thick] {1/ ( 1 + exp(-1.5*x))};
      \addlegendentry{$\alpha = 1.5$}
   \end{axis}
   
   \node[annot, yshift=0.5cm] at (relu.north) (xa) {Sigmoid};

\end{tikzpicture}

\begin{tikzpicture}[font=\large]
   \tikzstyle{arrow}=[->,draw=black!70, node distance=\layersep]
   \tikzstyle{every pin edge}=[<-,shorten <=1pt]
   \tikzstyle{neuron}=[circle,thick,draw=black,minimum size=17pt,inner sep=0pt]
   \tikzstyle{input}=[text=blue,minimum size=22pt];
   \tikzstyle{weight}=[neuron, minimum size=22pt];
   \tikzstyle{sum}=[neuron, minimum size=30pt];
   \tikzstyle{activation}=[neuron, rectangle, minimum size=30pt];
   \tikzstyle{annot} = [text width=20em, text centered];
   \tikzstyle{layerbg} = [rectangle, rounded corners];

   %\begin{axis}[
   %      ymin=0, ymax=1,
   %      xmin=-1, xmax=1,
   %      samples=50,
   %   ]
   %   \addplot[blue, ultra thick] {exp(x)};
   %\end{axis}  
   \begin{axis}[
         name=relu,
         axis line style = thick,
         xmin=-5, xmax=5,
         ymin=-1.2, ymax=1.2,
         xtick={0},
         ytick={-1,0,1},
         xlabel={$z$},
         ylabel={$g(z) = tanh(z)$},
         no markers,
         samples=500
      ]
      \addplot[blue,thick] {tanh(x)};
   \end{axis}
   
   \node[annot, yshift=0.5cm] at (relu.north) (xa) {Hyperbolic Tangent};

\end{tikzpicture}

\begin{tikzpicture}[font=\large]
   \tikzstyle{arrow}=[->,draw=black!70, node distance=\layersep]
   \tikzstyle{every pin edge}=[<-,shorten <=1pt]
   \tikzstyle{neuron}=[circle,thick,draw=black,minimum size=17pt,inner sep=0pt]
   \tikzstyle{input}=[text=blue,minimum size=22pt];
   \tikzstyle{weight}=[neuron, minimum size=22pt];
   \tikzstyle{sum}=[neuron, minimum size=30pt];
   \tikzstyle{activation}=[neuron, rectangle, minimum size=30pt];
   \tikzstyle{annot} = [text width=20em, text centered];
   \tikzstyle{layerbg} = [rectangle, rounded corners];

   %\begin{axis}[
   %      ymin=0, ymax=1,
   %      xmin=-1, xmax=1,
   %      samples=50,
   %   ]
   %   \addplot[blue, ultra thick] {exp(x)};
   %\end{axis}  
   \begin{axis}[
         name=relu,
         axis line style = thick,
         xmin=-5, xmax=5,
         ymin=-0.2, ymax=1.2,
         xtick={0},
         ytick={0,1},
         xlabel={$z$},
         ylabel={$g(z) = \zeta(z) = log \left( 1 + e^{z} \right)$},
         no markers,
         samples=500
      ]
      \addplot[blue,thick] {ln(1 + exp(x)) / exp(1)};
   \end{axis}
   
   \node[annot, yshift=0.5cm] at (relu.north) (xa) {Softplus};

\end{tikzpicture}

\end{document}
